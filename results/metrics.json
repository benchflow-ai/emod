{
  "vad_metrics": {
    "mse": [
      0.4892238676548004,
      0.3956588804721832,
      0.49306076765060425
    ],
    "rmse": [
      0.6994454264640808,
      0.6290141940116882,
      0.7021828293800354
    ],
    "mae": [
      0.527344286441803,
      0.5005399584770203,
      0.5674691200256348
    ],
    "r2": [
      0.4760007858276367,
      0.21759116649627686,
      0.2358909249305725
    ]
  },
  "emotion_metrics": {
    "accuracy": 0.594111461619348,
    "f1_weighted": 0.6051832443530835,
    "f1_macro": 0.5712188698988205,
    "classification_report": {
      "angry": {
        "precision": 0.7294117647058823,
        "recall": 0.6648793565683646,
        "f1-score": 0.6956521739130435,
        "support": 373.0
      },
      "happy": {
        "precision": 0.7431192660550459,
        "recall": 0.6532258064516129,
        "f1-score": 0.6952789699570815,
        "support": 248.0
      },
      "neutral": {
        "precision": 0.3400673400673401,
        "recall": 0.48792270531400966,
        "f1-score": 0.4007936507936508,
        "support": 207.0
      },
      "sad": {
        "precision": 0.5625,
        "recall": 0.43902439024390244,
        "f1-score": 0.4931506849315068,
        "support": 123.0
      },
      "accuracy": 0.594111461619348,
      "macro avg": {
        "precision": 0.593774592707067,
        "recall": 0.5612630646444724,
        "f1-score": 0.5712188698988205,
        "support": 951.0
      },
      "weighted avg": {
        "precision": 0.6266515306108148,
        "recall": 0.594111461619348,
        "f1-score": 0.6051832443530835,
        "support": 951.0
      }
    }
  },
  "data_info": {
    "total_samples": 6336,
    "train_samples": 4435,
    "val_samples": 950,
    "test_samples": 951,
    "emotion_distribution": {
      "angry": 2599,
      "happy": 1514,
      "neutral": 1352,
      "sad": 871
    }
  }
}