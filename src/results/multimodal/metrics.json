{
  "vad_metrics": {
    "mse": [
      0.45982825756073,
      0.4072696268558502,
      0.5122954845428467
    ],
    "rmse": [
      0.6781063675880432,
      0.6381767988204956,
      0.7157481908798218
    ],
    "mae": [
      0.5072412490844727,
      0.5015387535095215,
      0.5767711400985718
    ],
    "r2": [
      0.5074859857559204,
      0.19463109970092773,
      0.20608240365982056
    ]
  },
  "emotion_metrics": {
    "accuracy": 0.6140904311251314,
    "f1_weighted": 0.6178602758325716,
    "f1_macro": 0.5742551214140941,
    "classification_report": {
      "angry": {
        "precision": 0.7109375,
        "recall": 0.7319034852546917,
        "f1-score": 0.7212681638044914,
        "support": 373.0
      },
      "happy": {
        "precision": 0.7699530516431925,
        "recall": 0.6612903225806451,
        "f1-score": 0.7114967462039046,
        "support": 248.0
      },
      "neutral": {
        "precision": 0.3782771535580524,
        "recall": 0.48792270531400966,
        "f1-score": 0.42616033755274263,
        "support": 207.0
      },
      "sad": {
        "precision": 0.5287356321839081,
        "recall": 0.37398373983739835,
        "f1-score": 0.4380952380952381,
        "support": 123.0
      },
      "accuracy": 0.6140904311251314,
      "macro avg": {
        "precision": 0.5969758343462883,
        "recall": 0.5637750632466862,
        "f1-score": 0.5742551214140941,
        "support": 951.0
      },
      "weighted avg": {
        "precision": 0.6303532048923757,
        "recall": 0.6140904311251314,
        "f1-score": 0.6178602758325716,
        "support": 951.0
      }
    }
  },
  "data_info": {
    "total_samples": 6336,
    "train_samples": 4435,
    "val_samples": 950,
    "test_samples": 951,
    "emotion_distribution": {
      "angry": 2599,
      "happy": 1514,
      "neutral": 1352,
      "sad": 871
    },
    "fusion_type": "early"
  }
}