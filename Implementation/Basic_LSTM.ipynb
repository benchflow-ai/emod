{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"122a890a8f604909b9b4e60b1fc4cf71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62cf5bd6e67f4d72beb1e4fe9556c2b1","IPY_MODEL_d1eeb6aa2a724f18b2885e5a996b67a6","IPY_MODEL_d3c5b81f032e41cba3b309a441b2ee8e"],"layout":"IPY_MODEL_0c9cf8c1df9e421c953d9fcd8c71c49a"}},"62cf5bd6e67f4d72beb1e4fe9556c2b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_688051883f6d44789da6ca02213a4685","placeholder":"​","style":"IPY_MODEL_bdad5cb5be7940f696eb66484651c2aa","value":"Saving the dataset (1/1 shards): 100%"}},"d1eeb6aa2a724f18b2885e5a996b67a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d37dad1f90824df596ed8c5d7217a1c4","max":30160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ebe467e37c84c6f940cb715364a06a8","value":30160}},"d3c5b81f032e41cba3b309a441b2ee8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c4c48bb1fa94117ab73b8d388408684","placeholder":"​","style":"IPY_MODEL_4e1a9673e0054971aa441e7d412af6bb","value":" 30160/30160 [00:00&lt;00:00, 316771.61 examples/s]"}},"0c9cf8c1df9e421c953d9fcd8c71c49a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"688051883f6d44789da6ca02213a4685":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdad5cb5be7940f696eb66484651c2aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d37dad1f90824df596ed8c5d7217a1c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebe467e37c84c6f940cb715364a06a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c4c48bb1fa94117ab73b8d388408684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1a9673e0054971aa441e7d412af6bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"113095a323f64af1a9defea6f5f95513":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fc110f2a5d948249423675ff0989cdb","IPY_MODEL_ebace401d65d489581a341359635d9ea","IPY_MODEL_2a75b7951db9496abda43bf36ca2dac5"],"layout":"IPY_MODEL_44f49ac4677c47189df6e568803d677f"}},"6fc110f2a5d948249423675ff0989cdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d97ac11a4ee3443996223419cdbdc57d","placeholder":"​","style":"IPY_MODEL_c0588a2a48844e0d94baa94dc3e6f685","value":"Saving the dataset (1/1 shards): 100%"}},"ebace401d65d489581a341359635d9ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4555b546b1854937864868886060d009","max":5509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74af9ed2080b445b8f4fdc71e4024fad","value":5509}},"2a75b7951db9496abda43bf36ca2dac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9708a3f69a32471eadce66c7d8213181","placeholder":"​","style":"IPY_MODEL_22b3438887ec4f488452ec3f31efe769","value":" 5509/5509 [00:00&lt;00:00, 70417.85 examples/s]"}},"44f49ac4677c47189df6e568803d677f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d97ac11a4ee3443996223419cdbdc57d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0588a2a48844e0d94baa94dc3e6f685":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4555b546b1854937864868886060d009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74af9ed2080b445b8f4fdc71e4024fad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9708a3f69a32471eadce66c7d8213181":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22b3438887ec4f488452ec3f31efe769":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JtustNxxosF-"},"outputs":[],"source":["# Install TensorFlow and other required libraries\n","!pip install tensorflow\n","\n","# Import necessary libraries\n","import tensorflow as tf\n","import numpy as np\n"]},{"cell_type":"code","source":["pip install emoji==1.7"],"metadata":{"id":"legS4VNVDLxU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install spellchecker"],"metadata":{"id":"nS_lvGF5EBq5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n","\n","import argparse\n","import io\n","import json\n","import os\n","import re\n","import sklearn\n","import sys\n","\n","# Please use python 3.5 or above\n","import numpy as np\n","import tensorflow as tf\n","from emoji import UNICODE_EMOJI\n","from keras import optimizers\n","from keras.backend import argmax\n","from keras.layers import Dense, Embedding, LSTM, LeakyReLU, Concatenate, Input, Bidirectional, Conv1D, MaxPooling1D, \\\n","    Reshape, MaxPooling2D, Flatten, Dropout, Conv2D, MaxPooling2D\n","from keras.losses import categorical_crossentropy\n","from keras.metrics import categorical_accuracy, binary_accuracy\n","from keras.models import Sequential, Model\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","from spellchecker import SpellChecker\n","\n"],"metadata":{"id":"dRFCSLOgCQAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pyspellchecker"],"metadata":{"id":"nsz4myn_EUCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"id":"g4O-TTDXGWAC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# Define the dataset name\n","dataset_name = \"emo\"\n","\n","# Load the dataset\n","dataset = load_dataset(dataset_name)\n","\n","# Print some information about the dataset\n","print(dataset)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mP2SKJIUF3q8","outputId":"1e176ba6-2c01-44bb-c93c-d27e9700a715"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 30160\n","    })\n","    test: Dataset({\n","        features: ['text', 'label'],\n","        num_rows: 5509\n","    })\n","})\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","# Define the dataset name\n","dataset_name = \"emo\"\n","\n","# Load the dataset\n","dataset = load_dataset(dataset_name)\n","\n","# Save the dataset to a directory in your Colab environment\n","save_path = \"/content/dataset\"  # Change this to your desired save path\n","dataset.save_to_disk(save_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["122a890a8f604909b9b4e60b1fc4cf71","62cf5bd6e67f4d72beb1e4fe9556c2b1","d1eeb6aa2a724f18b2885e5a996b67a6","d3c5b81f032e41cba3b309a441b2ee8e","0c9cf8c1df9e421c953d9fcd8c71c49a","688051883f6d44789da6ca02213a4685","bdad5cb5be7940f696eb66484651c2aa","d37dad1f90824df596ed8c5d7217a1c4","2ebe467e37c84c6f940cb715364a06a8","2c4c48bb1fa94117ab73b8d388408684","4e1a9673e0054971aa441e7d412af6bb","113095a323f64af1a9defea6f5f95513","6fc110f2a5d948249423675ff0989cdb","ebace401d65d489581a341359635d9ea","2a75b7951db9496abda43bf36ca2dac5","44f49ac4677c47189df6e568803d677f","d97ac11a4ee3443996223419cdbdc57d","c0588a2a48844e0d94baa94dc3e6f685","4555b546b1854937864868886060d009","74af9ed2080b445b8f4fdc71e4024fad","9708a3f69a32471eadce66c7d8213181","22b3438887ec4f488452ec3f31efe769"]},"id":"JsaEklCRMrPb","outputId":"00239ec7-b2e8-4453-fd34-3da870a74dca"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/30160 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"122a890a8f604909b9b4e60b1fc4cf71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/5509 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"113095a323f64af1a9defea6f5f95513"}},"metadata":{}}]},{"cell_type":"code","source":["def clean_text(text):\n","    # Remove special characters and punctuation\n","    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Tokenize (split the text into words)\n","    tokens = text.split()\n","    # Join tokens back into a string\n","    cleaned_text = \" \".join(tokens)\n","    return cleaned_text\n","train_dataset = dataset[\"train\"]\n","test_dataset = dataset[\"test\"]\n","\n","# Clean and preprocess the training data\n","cleaned_train_data = [clean_text(example[\"text\"]) for example in train_dataset]\n","\n","# Clean and preprocess the test data\n","cleaned_test_data = [clean_text(example[\"text\"]) for example in test_dataset]\n","\n","# Print the cleaned data (first few examples)\n","print(\"Cleaned Training Data (First 5 examples):\")\n","for i in range(5):\n","    print(cleaned_train_data[i])\n","\n","print(\"\\nCleaned Test Data (First 5 examples):\")\n","for i in range(5):\n","    print(cleaned_test_data[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-JM-rXqPhXn","outputId":"6f17d7a6-c5ec-4603-a11f-e022824efcb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned Training Data (First 5 examples):\n","don t worry i m girl hmm how do i know if you are what s ur name\n","when did i saw many times i think no i never saw you\n","by by google chrome where you live\n","u r ridiculous i might be ridiculous but i am telling the truth u little disgusting whore\n","just for time pass wt do u do 4 a living then maybe\n","\n","Cleaned Test Data (First 5 examples):\n","hmm what does your bio mean i dont have any bio\n","what you like very little things ok\n","yes how so i want to fuck babu\n","what did you guess what what fuck\n","we of course we will what gender movies you like\n"]}]},{"cell_type":"code","source":["import re\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from datasets import load_dataset"],"metadata":{"id":"1bxVDZGeQEq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNLXeEwaQF_P","outputId":"4dbbbee2-4ff8-4449-9be8-2408a15173be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxZcY_ZbQZhK","outputId":"ebe3321d-db6c-445b-bf72-0de82468e84d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["\n","def preprocess_text(text):\n","    # Remove special characters and punctuation\n","    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Tokenize (split the text into words)\n","    tokens = text.split()\n","\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","    # Join tokens back into a string\n","    preprocessed_text = \" \".join(tokens)\n","    return preprocessed_text\n","\n","# Preprocess the training data\n","preprocessed_train_data = [preprocess_text(example[\"text\"]) for example in train_dataset]\n","\n","# Preprocess the test data\n","preprocessed_test_data = [preprocess_text(example[\"text\"]) for example in test_dataset]\n","\n","# Print the preprocessed data (first few examples)\n","print(\"Preprocessed Training Data (First 5 examples):\")\n","for i in range(5):\n","    print(preprocessed_train_data[i])\n","\n","print(\"\\nPreprocessed Test Data (First 5 examples):\")\n","for i in range(5):\n","    print(preprocessed_test_data[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpGRgWt4P8Jt","outputId":"df8dedf9-319b-44b2-d8e5-8ba18f47fac0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessed Training Data (First 5 examples):\n","don t worry i m girl hmm how do i know if you are what s ur name\n","when did i saw many time i think no i never saw you\n","by by google chrome where you live\n","u r ridiculous i might be ridiculous but i am telling the truth u little disgusting whore\n","just for time pas wt do u do 4 a living then maybe\n","\n","Preprocessed Test Data (First 5 examples):\n","hmm what doe your bio mean i dont have any bio\n","what you like very little thing ok\n","yes how so i want to fuck babu\n","what did you guess what what fuck\n","we of course we will what gender movie you like\n"]}]},{"cell_type":"code","source":["MAX_NB_WORDS = 5000  # Maximum number of unique words in the vocabulary\n","MAX_SEQUENCE_LENGTH = 100  # Maximum length of a text sequence\n","EMBEDDING_DIM = 50  # Dimension of word embeddings\n","NUM_CLASSES = 4  # Number of classes in the dataset\n","BATCH_SIZE = 64  # Batch size for training\n","NUM_EPOCHS = 10  # Number of training epochs"],"metadata":{"id":"wNPdo00oRrLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n","tokenizer.fit_on_texts(preprocessed_train_data)\n","train_sequences = tokenizer.texts_to_sequences(preprocessed_train_data)\n","train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","# Tokenize and pad the test data\n","test_sequences = tokenizer.texts_to_sequences(preprocessed_test_data)\n","test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","\n","# Convert labels to one-hot encoding\n","train_labels = to_categorical(np.asarray(train_dataset[\"label\"]), num_classes=NUM_CLASSES)\n","\n","# Build an embedding matrix\n","word_index = tokenizer.word_index\n","embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n","\n","# Load pre-trained word embeddings (e.g., GloVe embeddings)\n","# You can replace this with your path to the word embeddings file\n","glove_path = \"glove.txt\"\n","embeddings_index = {}\n","with open(glove_path, encoding=\"utf8\") as f:\n","    for line in f:\n","        values = line.split()\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype=\"float32\")\n","        embeddings_index[word] = coefs\n","\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","# Build and train a model\n","model = Sequential()\n","model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","# Train the model\n","model.fit(train_data, train_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)\n","\n","# Make predictions on the test data\n","test_predictions = model.predict(test_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"oqo658q9Rod9","outputId":"89f0c6a6-6923-4af9-949d-ddf2cc22f314","executionInfo":{"status":"error","timestamp":1699315750597,"user_tz":480,"elapsed":380,"user":{"displayName":"Abhinay Jatoth","userId":"18209564711180140509"}}},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1e3dca5bbd0f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_NB_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n","\n","# Ground truth labels (true values) from the test dataset\n","true_labels = test_dataset[\"label\"]\n","\n","# Predicted labels from the model\n","predicted_labels = np.argmax(test_predictions, axis=1)  # Convert one-hot to categorical labels\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","print(f\"Accuracy: {accuracy:.2f}\")\n","\n","# Calculate precision, recall, and F1-score\n","precision = precision_score(true_labels, predicted_labels, average=\"weighted\")\n","recall = recall_score(true_labels, predicted_labels, average=\"weighted\")\n","f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n","\n","print(f\"Precision: {precision:.2f}\")\n","print(f\"Recall: {recall:.2f}\")\n","print(f\"F1-Score: {f1:.2f}\")\n","\n","# Print classification report\n","class_names = [\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\"]  # Adjust class names based on your dataset\n","report = classification_report(true_labels, predicted_labels, target_names=class_names)\n","print(\"Classification Report:\\n\", report)\n","\n","# Generate a confusion matrix\n","confusion = confusion_matrix(true_labels, predicted_labels)\n","print(\"Confusion Matrix:\\n\", confusion)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"DCcto7dpiXpS","outputId":"090474c0-9a5e-4e21-bffb-bf2b60010c60","executionInfo":{"status":"error","timestamp":1699314297210,"user_tz":480,"elapsed":1658,"user":{"displayName":"Abhinay Jatoth","userId":"18209564711180140509"}}},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-a15a5f574bf0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ground truth labels (true values) from the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Predicted labels from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"b8pnvulhBlCK"},"execution_count":null,"outputs":[]}]}